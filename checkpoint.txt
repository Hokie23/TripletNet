2016.3.21. 
    Distance값이 생각보다 큰 범위가 나온다. 이 부분의 타당성을 체크해 보자.
    3.22    정규화는 정확하게 되었다.
2016.3.21. 
    Failed) 거리 계산 통계를 낼때 network을 test모드로 하지 않았다. 
        ex) PM 8:11에 데이터 시작--> inter- vs. intra- class의 거리차가 발생했으면 좋겠다.
        3.22    확실히 test 모드의 버그였다.
                큰 수치는 아니지만 두 값의 차이를 갇는 히스토그램을 만들었다.
2016.3.22
    512 dim이 128 dim보다 distinctiveness을 더 준다.
    Next Check Point?
        1024로 하였을 경우 distinctiveness을 더 줄 것인가?
        Grid는 타당성이 적어 보인다? 이유는 center alignment가 적다.
        Object detector의 alignment을 시켜서 했을 경우는 어떠한가?
        Object detector + Grid Concept을 하였을 경우는 어떠한가?
        Object Aggregation 할때 LSTM으로 혼합 비율인(a)를 계산하는 훈련 학습을 하는 것은 어떠한가?
        * Grid방식인데, 어떠한 feature를 선택하느냐고 중요한 것 같다.
            Mask 방식이면 어떠한가?

2016.3.23
    512 dim 일경우, 0.03의 기대값의 차이가 난다.
    KL-Divergence로 두 확률 분포도의 차이를 계산해 보자.
        128: 0.20620520017498
        512: 0.15001921253361
        512_a: 0.1565341284894
        1024: 0.14499436916698
        1024(relu): 0.21344076569702

        512와 512_a는 성능면에서 0.003와 0.04이다. 그러나 성능은 별반 차이가 없다.

2016.3.28
    BUG! Test 수행시 input 영상의 값의 범위를 정규화 하지 않았다.
    정규화 하였을 경우 성능이 개선되면 좋겠다.
    KL-Divergence가 1024dim: 0.21344076569702 -> 0.28187941423906, 128dim: 0.19030086547211 -> 0.25631769486686 로 개선되었다. 그러나 그래프 모양은 달라지지 않고 양끝을 늘어트린 느낌입니다.

2016. 3. 28. 
    Feature를 추출하는 코드를 작성하자!

2016. 3. 28.
    Feature Folder List
        512: Results/MonMar2116:45:482016
        128D: Results/WedMar2314:56:452016
        1024D: Results/WedMar2319:55:362016

2016. 4. 1.
    Pair로 훈련하지 않은 1024D가 pair로 훈련한 1024D보다  더 좋은 성능을 나타냈다.
        왜 그럴까?: 
            1. overfitting?
                1. validation을 그려보야야 겠다.
                2. Training set을 그려보야야 겠다.
            2. Network Architcture 구조적 문제?
            3. Loss function 문제?
            4. 샘플의 문제?
                1. 구축의 문제
                2. 개수의 문제
            5. Input 차원의 jittering 문제?
            6. Pretrain model을 바꾸어 볼까?
                이것은 이미 2048에서 1024와 동일한 결과를 내었다.
            7. Training Set에 대한 성능은?
                이상하게 traning set에서도 성능이 떨어지는 느낌을 받는다.


2016. 4. 7.
    Shared Weight를 제대로 저장하는 것인지 체크가 필요하다.

2016.5.11. Output distance 조절
    1.0으로 고정시켜놓고 threshold value보다 작은 것을 target으로 맞추는 과정은 성능이 떨어 졌다.
    Output Distance를 서서히 올리면서 학습하는 것이 좋은 성능을 가졌다. 고정보다 서서히 올리는 것이 성능이 좋게 나왔다.
    Adaptive Target Distance 1.02로 부조건적으로 에러를 증가시면서 하면은 어떻게 될까? 
    SoftMax기법은 어떠한가?
    Distance에 Offset을 넣어 보자. Query마다 최대로 가까운 거리가 차이가 있다.
2016.5.18. Output Distanc vs adaptive distance의 실험 결과 체크

